models:
  Generator:
    name: "UNet3D"
    type: "UNet3D"
    params:
      in_channels: 1
      out_channels: 1
      interpolate: True
      leaky: True
    optimizer:
      type: "SGD"
      params:
        lr: 0.001
        momentum: 0.9
        weight_decay: 0.001
    scheduler:
      type: "MultiStepLR"
      params:
        milestones: [50, 75]
        gamma: 0.1
    criterion:
      MSELoss:
        type: "MSELoss"
    metrics:
      MeanSquaredError:
        type: "MeanSquaredError"

  Segmenter:
    name: "UNet3D"
    type: "UNet3D"
    params:
      in_channels: 1
      out_channels: 4
      interpolate: True
      leaky: True
    optimizer:
      type: "SGD"
      params:
        lr: 0.001
        momentum: 0.9
        weight_decay: 0.001
    scheduler:
      type: "ReduceLROnPlateau"
      params:
        factor: 0.1
        patience: 7
        min_lr: 0.00000001
    criterion:
      DiceLoss:
        type: "DiceLoss"
        params:
          reduction: !!null
          ignore_index: -100
          weight: !torch/tensor [0.22, 0.28, 0.20, 0.30]
    metrics:
      Dice:
        type: "Dice"
        params:
          num_classes: 4
          reduction: !!null
          ignore_index: 0
          average: !!null
          weight: !!null
      IoU:
        type: "IoU"
        params:
          num_classes: 4
          reduction: !!null
          ignore_index: 0
          average: !!null
          weight: !!null
      Accuracy:
        type: "Accuracy"
      Precision:
        type: "Precision"
        params:
          average: True
      Recall:
        type: "Recall"
        params:
          average: True

dataset:
  MRBrainS:
    path: "/project/def-lombaert/pld2602/Data/MRBrainS/DataNii/TrainingData/"
    path_augmented: !!null
    modalities: "T1"
    max_subjects: !!null
    max_num_patches: 40000
    validation_split: 0.3
    hist_shift_augmentation: False
    patch_size: !python/tuple [1, 32, 32, 32]
    step: [1, 4, 4, 4]
    test_patch_size: !python/tuple [1, 64, 64, 64]
    test_step: [1, 16, 16, 16]
    reconstruction_size: [256, 256, 192]

training:
  trainer: "DualUNet"
  batch_size: 72
  n_critics: 3
  nb_epochs: 150
  patience_segmentation: 0
  build_augmented_images: False
  data_augmentation: False
  variables:
    disc_ratio: 1.0
    seg_ratio: 1.0

visdom:
  server: "10.180.113.44"
  port: "8097"
  env: "DualUNet_canada_mrbrains_dataset"
  offline: True
  filename: "DualUNet_canada_mrbrains_dataset.json"
